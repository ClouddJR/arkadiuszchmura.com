[{"content":"Introduction Recently, I\u0026rsquo;ve been working on a codebase where I had to write a bridging code between a data layer using Flows and a UI layer that still relied on the state exposed as LiveData.\nLuckily, there is a function in the androidx.lifecycle called asLiveData() that allows you to convert a Flow to a LiveData effortlessly. However, there is one caveat to keep in mind when using a LiveData created this way. It will only emit data when it has at least one active observer. If there is an update to the upstream flow and the LiveData is inactive, it will not have the latest value.\nLet me show you a potential problem we might encounter, with an example below:\nExample We have a simple activity that keeps a reference to an AAC ViewModel:\nclass MainActivity : AppCompatActivity() { private val viewModel: MainViewModel by viewModels() override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) } } The MainViewModel looks like this:\nclass MainViewModel : ViewModel() { private val repository = Repository() val state: LiveData\u0026lt;Int\u0026gt; = repository.state.asLiveData() } We have a reference to a repository that will act as our trivial data layer. The ViewModel also exposes a state as a LiveData object converted from a StateFlow kept inside the repository using the asLiveData() function mentioned before.\nHere is what the repository looks like:\nclass Repository { private val _state = MutableStateFlow(-1) val state: StateFlow\u0026lt;Int\u0026gt; = _state suspend fun update() { _state.emit(Random.nextInt(until = 1000)) } } It\u0026rsquo;s a simple class with a StateFlow wrapping an integer (that starts with an initial value of -1) that also has a method allowing clients to update the state with a new random number between 0 and 1000.\nLet\u0026rsquo;s imagine we want to schedule the update as soon as our activity is created. We could do this by creating a method inside the MainViewModel called init() that we would call inside the onCreate() of our activity:\n// MainViewModel fun init() { // update() is suspending, so we launch a new coroutine here viewModelScope.launch { repository.update() } } // MainActivity override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) viewModel.init() } Now, during the creation of our activity, a new coroutine will be launched that will eventually call update() on the repository, generating a random number and emitting it to the state.\nAdditionally, let\u0026rsquo;s suppose that there is a requirement to send an analytical event containing the newly generated number in our ViewModel. We could write a sendAnalyticalEvent() method in our ViewModel that we will run right after calling the update() method on the repository:\n// MainViewModel fun init() { viewModelScope.launch { repository.update() sendAnalyticalEvent() // \u0026lt;-- NEW } } private fun sendAnalyticalEvent() { // Typically, we would schedule a network request here val liveDataValue = state.value val flowValue = repository.state.value Log.d(\u0026#34;Current number in LiveData\u0026#34;, \u0026#34;$liveDataValue\u0026#34;) Log.d(\u0026#34;Current number in StateFlow\u0026#34;, \u0026#34;$flowValue\u0026#34;) } Inside this method, we would typically schedule a network request to our backend servers but in this case, let\u0026rsquo;s see both values from the LiveData and Flow in the Logcat instead:\nNow, that is quite unexpected. You could argue that the LiveData doesn\u0026rsquo;t have the newest value because there wasn\u0026rsquo;t enough time to collect it from the upstream flow, and you might be right. But in this case, not only does the LiveData contain an incorrect value, but it\u0026rsquo;s null! And remember, the initial value of the state in the repository was -1. It can only mean one thing - our LiveData didn\u0026rsquo;t collect anything from the StateFlow.\nThe reason is that we haven\u0026rsquo;t started observing the LiveData anywhere. Therefore, it\u0026rsquo;s considered inactive. And, according to the documentation of the asLiveData() function, in this state, LiveData won\u0026rsquo;t be collecting any values from the upstream flow:\nCreates a LiveData that has values collected from the origin Flow.\nThe upstream flow collection starts when the returned LiveData becomes active (LiveData.onActive). If the LiveData becomes inactive (LiveData.onInactive) while the flow has not completed, the flow collection will be cancelled after timeoutInMs milliseconds unless the LiveData becomes active again before that timeout (to gracefully handle cases like Activity rotation).\nOnce we start observing the state in our activity (hence making the LiveData active), it will contain the correct (newest) value:\n// MainActivity override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) viewModel.init() viewModel.state.observe(this) { // \u0026lt;-- NEW Log.d(\u0026#34;Current number in MainActivity\u0026#34;, \u0026#34;$it\u0026#34;) } } And this is the output from the Logcat:\nIn this example, we use StateFlow, but the same rules apply to SharedFlow. Furthermore, it would be even worse because any events sent to a SharedFlow while the LiveData is inactive would be permanently lost (SharedFlow, by default, doesn\u0026rsquo;t replay any values to new subscribers).\nSummary Keep in mind that LiveData converted from a Flow using the asLiveData() function will behave slightly differently than expected. It will emit data only when there are active observers. To me, this behavior makes sense because we generally wouldn\u0026rsquo;t be interested in LiveData values if we didn\u0026rsquo;t observe it anywhere.\nRegardless, there might be some use cases when you want to access the current value of your LiveData in your ViewModel before you start observing it. After reading this post, I hope you won\u0026rsquo;t be surprised when encountering seemingly incorrect values in such situations.\n","permalink":"https://arkadiuszchmura.com/posts/be-careful-when-converting-flow-to-livedata/","summary":"LiveData created this way will only emit data when it has active observers.","title":"Be careful when converting Flow to LiveData"},{"content":"Introduction Imagine you spill a cup of coffee onto your laptop keyboard one day. The damage is permanent, and you desperately need a new machine.\nNow, ask yourself a question. How long would it take to bring your new machine to the previous state? That includes all user settings, editors and shell configurations, installed apps, and more.\nIf the answer is \u0026ldquo;a couple of days\u0026rdquo;, or even worse, \u0026ldquo;a couple of weeks\u0026rdquo;, continue reading to find out what you can do about that.\nThis post will show you how and where I store all my configuration files (dotfiles) to make switching between many machines a breeze.\nEven though it might be quite an investment of time initially to set everything up, it will undoubtedly pay off in the future.\nRepository I keep all my dotfiles and initializing scripts in a repository on GitHub. Feel free to use it as a template and adjust it to your needs and preferences. I, for example, was inspired by Freek Van der Herten\u0026rsquo;s repository.\nEvery time I want to set up a new machine, I clone my repository and run these simple commands:\nchmod +x bootstrap ./bootstrap Then, I follow the instructions on the screen which will do the job for me:\nI usually go through all of these options sequentially when starting from scratch. Let\u0026rsquo;s explain what each of them does:\n1. Bootstrap terminal As the name suggests, this step is responsible for bootstrapping my terminal, which includes:\nHiding the \u0026ldquo;last login\u0026rdquo; line when starting a new session. Installing oh-my-zsh. My terminal of choice is iTerm2. I\u0026rsquo;m using the Z shell with oh-my-zsh. It has a lot of valuable functions, plugins, helpers, and more. I highly recommend this combination. Creating symbolic links for .zsrhc and .vimrc. The latter contains a basic configuration for Vim. The former stores all the exports, aliases, and functions I frequently use when working on the shell. It also configures the theme (robbyrussell) and specifies used plugins (in my case: git, adb, macos, and laravel). Usually, plugins will give you auto-completion for specific commands and some useful aliases. Check out the Wiki for a complete list of plugins for oh-my-zsh. For example, here\u0026rsquo;s what the auto-completion looks like for the adb plugin. As you can see, I can also navigate between suggested options using arrows, which is very convenient: Sometimes I want to export variables (or aliases and functions) that I wouldn\u0026rsquo;t store in a public repository for security reasons. In that case, I can create a .dotfiles-custom folder that git does not track, and the .zshrc will also load everything from there.\nActivating z.sh. If you\u0026rsquo;ve never used it before, do yourself a favor and try it. It\u0026rsquo;s a tremendously helpful and popular bash script for quick navigation between visited directories on your file system. For example, if you want to cd into a deeply nested directory (like Development/Mobile/Android/MyProject), you don\u0026rsquo;t have to specify the entire path. It\u0026rsquo;s enough to type z project to get there immediately (provided you have visited this directory before so that the script could save it in local history). It also works for sibling directories, as you can see below: Installing and setting up Homebrew. This package manager probably needs no introduction for macOS users. This substep also includes installing packages I use on most computers, like git, python, java, node, mysql, etc. 2. Install applications You might be surprised that you can install regular GUI applications for macOS (those that require downloading .dmg files and running the installer) without leaving the terminal. It\u0026rsquo;s possible thanks to an extension to Homebrew called Homebrew Cask. Installing an application is as easy as running a single command (provided it\u0026rsquo;s available as a Cask):\nbrew install --cask firefox This setup\u0026rsquo;s step is straightforward. It\u0026rsquo;s responsible for installing some apps (listed in the repository) using the above method.\nSome apps, like IDEs, have their own configurations, which might include custom keyboard shortcuts, formatting styles, etc. I also keep them in my repository (in most cases as zip files) to easily import these configs after installation.\n3. Set system defaults (macOS) Here, the script specifies values for some system preferences, like disabling the sound effect on boot or showing all file extensions by default in Finder. There\u0026rsquo;s no shortage of things you can do. To learn more and get some inspiration, here\u0026rsquo;s a helpful website with some demos: https://macos-defaults.com.\nSummary I hope I convinced you that it\u0026rsquo;s worth setting up your dotfiles repository to have a single place where all your configurations lie. Thanks to that, switching between many machines will be a piece of cake.\nIf you have some tips that you would like to share with me regarding this topic, feel free to reach me on Twitter.\n","permalink":"https://arkadiuszchmura.com/posts/managing-dotfiles-with-github/","summary":"This post will describe how I store and manage my dotfiles in a repository on GitHub.","title":"Managing dotfiles with GitHub"},{"content":"Introduction In this post, I would like to show you how you can draw content behind the system bars (status bar or navigation bar) when building a UI using Jetpack Compose.\nA typical use case (that will be the focus of this post) is when you have an app bar or a navigation bar in your app and want to lay them out behind the system bars to achieve an effect of connectedness between system UI components and your app.\nIt can give your app a more compelling and modern user experience that adheres to the Material 3 guidelines.\nSolution To illustrate all the necessary steps, we will start with a basic app that has a CenterAlignedTopAppBar, NavigationBar, and a LazyColumn containing some items.\nI created the project using the Empty Compose Activity template from the Android Studio\u0026rsquo;s project wizard. The generated code will make the navigation bar black by default, while the status bar will use the primary color specified in the theme.\nHere\u0026rsquo;s what the app looks like:\nAnd here\u0026rsquo;s the code (without any irrelevant parts). Firstly, MainActivity:\nclass MainActivity : ComponentActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContent { App() } } } @OptIn(ExperimentalMaterial3Api::class) @Composable fun App() { AppTheme { val scrollBehavior = TopAppBarDefaults.pinnedScrollBehavior() Scaffold( topBar = { CenterAlignedTopAppBar( title = { Text(\u0026#34;Title\u0026#34;) }, scrollBehavior = scrollBehavior ) }, bottomBar = { NavigationBar { NavigationBarItem( selected = true, icon = { Icon(imageVector = Icons.Default.Home, contentDescription = \u0026#34;\u0026#34;) }, label = { Text(\u0026#34;First\u0026#34;) }, onClick = { } ) NavigationBarItem( selected = false, icon = { Icon(imageVector = Icons.Default.Face, contentDescription = \u0026#34;\u0026#34;) }, label = { Text(\u0026#34;Second\u0026#34;) }, onClick = { } ) } } ) { paddingValues -\u0026gt; Surface( modifier = Modifier .padding(paddingValues) .fillMaxSize() ) { LazyColumn( modifier = Modifier.nestedScroll(scrollBehavior.nestedScrollConnection), contentPadding = PaddingValues(16.dp), verticalArrangement = Arrangement.spacedBy(8.dp) ) { items(count = 100) { Text(\u0026#34;Hello Android!\u0026#34;) } } } } } } And this is the body of the AppTheme function:\n@Composable fun AppTheme( darkTheme: Boolean = isSystemInDarkTheme(), dynamicColor: Boolean = true, content: @Composable () -\u0026gt; Unit ) { val colorScheme = when { dynamicColor \u0026amp;\u0026amp; Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.S -\u0026gt; { val context = LocalContext.current if (darkTheme) dynamicDarkColorScheme(context) else dynamicLightColorScheme(context) } darkTheme -\u0026gt; DarkColorScheme else -\u0026gt; LightColorScheme } val view = LocalView.current if (!view.isInEditMode) { SideEffect { val window = (view.context as Activity).window window.statusBarColor = colorScheme.primary.toArgb() WindowCompat.getInsetsController(window, view).isAppearanceLightStatusBars = darkTheme } } MaterialTheme( colorScheme = colorScheme, typography = Typography, content = content ) } Notice the use of val scrollBehavior = TopAppBarDefaults.pinnedScrollBehavior() at the beginning of the App composable. Thanks to this, we get that nice visual effect of elevation on the app bar when scrolling the list.\nTo utilize it, we first pass the created scrollBehavior to the CenterAlignedTopAppBar. Next, we attach its nestedScrollConnection to the Modifier.nestedScroll on the LazyColumn that will keep track of scroll events and notify the app bar about them.\nAs you can see above, the user interface in our sample app is far from perfect. The black color of the navigation bar doesn\u0026rsquo;t play nicely with our design. Also, no matter whether the app bar is elevated or not, the status bar has always the same color.\nIdeally, we would like the system navigation bar to have the same color as our app\u0026rsquo;s navigation bar. The same goes for the status bar. It should change colors based on the app bar\u0026rsquo;s current elevation.\nHere\u0026rsquo;s the final effect that we would like to achieve:\nLuckily, it\u0026rsquo;s not that complicated. There are only two steps we need to introduce to our code presented above:\nLaying out our app in full screen. Changing the system bar colors and transparency. Laying out our app in full screen A single line of code is enough to make sure our app goes edge-to-edge and is laid out using the entire width and height of the display (including the system bars). We can place it inside the onCreate method in our activity:\noverride fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) // This will lay out our app behind the system bars WindowCompat.setDecorFitsSystemWindows(window, false) setContent { App() } } Changing the system bar colors and transparency After drawing our content behind the system bars we need to make sure it\u0026rsquo;s visible to the user. We can do that by setting the color of the navigation bar and the status bar to transparent.\nIf you are interested, I wrote an entire post about changing the system bar colors in Compose.\nHere is the relevant part of the AppTheme function:\nSideEffect { val window = (view.context as Activity).window window.statusBarColor = Color.Transparent.toArgb() window.navigationBarColor = Color.Transparent.toArgb() if (Build.VERSION.SDK_INT \u0026gt;= Build.VERSION_CODES.Q) { window.isNavigationBarContrastEnforced = false } val windowsInsetsController = WindowCompat.getInsetsController(window, view) windowsInsetsController.isAppearanceLightStatusBars = !darkTheme windowsInsetsController.isAppearanceLightNavigationBars = !darkTheme } Firstly, we set the system bar colors to transparent. Next, we tell the system not to enforce the navigation bar contrast, because by default, on API \u0026gt;= 29, the system applies a translucent scrim behind the system bars. Lastly, we modify the icon colors to match the current theme (light or dark).\nNow, after running the app, we get the desired effect and our app looks much better!\nNotice that even though we draw our app bar and navigation bar behind the system bars, their content (titles, icons, etc.) doesn\u0026rsquo;t interfere with the system bars. That\u0026rsquo;s because since version 1.0.0-beta01 of the androidx.compose.material3:material3, these components handle insets automatically and apply correct padding values based on them.\nIf we used previous versions, we would have to do it manually. If you are interested in how it used to be done, here is the commit from the Now in Android project that removes manual insets handling after bumping the library version.\nSummary I hope this post will save you some time when you try to draw some UI components behind the system bars.\nIf you have any questions or comments, feel free to reach me on Twitter.\n","permalink":"https://arkadiuszchmura.com/posts/how-to-draw-content-behind-system-bars-in-jetpack-compose/","summary":"It\u0026rsquo;s a typical use case, but it\u0026rsquo;s hard to find a concrete example in the documentation.","title":"How to draw content behind system bars in Jetpack Compose"},{"content":"Introduction Let\u0026rsquo;s look at a simple suspending function that fetches some data from a server. Before executing a network call, it sets the isLoading variable to true. Then, after finishing successfully, it sets it back to false and returns the loaded data:\nclass Repository { var isLoading = false suspend fun fetchData(): String { isLoading = true delay(500) // Simulate a network call isLoading = false return \u0026#34;Loaded data\u0026#34; } } For simplicity, let\u0026rsquo;s ignore all the additional things we would normally take care of in a real project, like error handling, making the actual network call, parsing the result, etc. Instead, let\u0026rsquo;s focus on the aspect of testing this snippet of code.\nTesting the final result of the fetchData function is relatively easy with the help of some tools from the kotlinx.coroutines.test library. This is what such a test could look like:\n@Test fun `repository should return loaded data`() = runTest { // given val repository = Repository() // when val result = repository.fetchData() // then assertEquals(\u0026#34;Loaded data\u0026#34;, result) } Notice how this test doesn\u0026rsquo;t look much different than what we would write if we were testing a regular function.\nrunTest is an extremely convenient function. It behaves similarly to runBlocking, with the difference that the code that it runs will skip delays. Thanks to this, we don\u0026rsquo;t have to wait 500 ms (because of the delay(500) in our fetchData function) for the test to finish.\nThe code above works just fine, but what if we want to have more control over this test? We would like to make sure that the fetchData function indeed sets correct values to the isLoading variable - before and after making a network call.\nSolution We can take advantage of the fact that runTest executes our test body in a new coroutine launched on a TestScope.\nThis scope uses a special kind of dispatcher - StandardTestDispatcher. Usually, dispatchers are used to control the thread on which our coroutines should run. This dispatcher does a bit more - it supports delay-skipping using a scheduler that operates on virtual time (TestCoroutineScheduler).\nCoroutines started with the StandardTestDispatcher won\u0026rsquo;t run immediately. Instead, the dispatcher always sends them to its scheduler. Then, it\u0026rsquo;s our job to trigger their execution by controlling the virtual time. For this, we can use functions available on the TestCoroutineScheduler: advanceTimeBy, runCurrent or advanceUntilIdle.\nTo see this in action, look at the code below:\n@Test fun `child coroutine`() = runTest { // 1 launch { // 3 } // 2 advanceUntilIdle() // Run all the scheduled tasks // 4 } When we call launch, the coroutine is not executed immediately. Instead, as mentioned earlier, it\u0026rsquo;s sent to the scheduler. Only when we call advanceUntilIdle (or any other function controlling the virtual time), the child coroutine is executed.\nNotice that we can call advanceUntilIdle directly on the TestScope. It\u0026rsquo;s because it\u0026rsquo;s defined as an extension function that internally delegates the call to the scheduler. The same is true for the remaining functions modifying the virtual time.\nThis behavior allows us to call the function we want to test inside a child coroutine. That coroutine will be sent to the scheduler and its execution is fully controllable by us.\nWe can advance the virtual time to the point where the data is about to be loaded and verify that the isLoading is properly set to true. Then we can run all the tasks scheduled at that time (remember the delay(500) that we had in our function?) by using runCurrent. Lastly, we can assert that the isLoading variable is back to false:\n@Test fun `repository should indicate that it\u0026#39;s loading data`() = runTest { // given val repository = Repository() launch { repository.fetchData() } // when advanceTimeBy(500) // then assertTrue(repository.isLoading) // when runCurrent() // then assertFalse(repository.isLoading) } Regular functions that launch coroutines Previously, we looked at testing intermediate steps in suspending functions. But in some cases, we want to test a regular, non-suspending function that launches a new coroutine inside. It\u0026rsquo;s very common in many Android projects where you can see a code similar to this one:\nclass TasksViewModel(private val repository: TasksRepository) : ViewModel() { private val _isLoading = MutableStateFlow(false) val isLoading: StateFlow\u0026lt;Boolean\u0026gt; = _isLoading fun getTasks() { viewModelScope.launch { _isLoading.emit(true) repository.getTasks() _isLoading.emit(false) } } } We have a ViewModel that exposes a function called getTasks. Internally, it launches a new coroutine using a viewModelScope in which it calls a suspending function getTasks from our repository. Besides, it correctly updates the isLoading state before and after.\nHere\u0026rsquo;s what the TasksRepository looks like (including the implementation that will be used in tests):\ninterface TasksRepository { suspend fun getTasks(): List\u0026lt;Task\u0026gt; } class InMemoryTasksRepository : TasksRepository { override suspend fun getTasks(): List\u0026lt;Task\u0026gt; { delay(500) // Simulate a network call return listOf( Task(\u0026#34;1\u0026#34;, \u0026#34;Task 1\u0026#34;), Task(\u0026#34;2\u0026#34;, \u0026#34;Task 2\u0026#34;) ) } } data class Task(val id: String, val name: String) We can\u0026rsquo;t directly use the same approach as previously, because the coroutine inside getTasks is launched on the viewModelScope. This scope knows nothing about the TestScope that is running our test body. This means that viewModelScope.launch {...} would be launched immediately instead of being scheduled by the StandardTestDispatcher.\nTo solve this, we need to force the viewModelScope to use the StandardTestDispatcher that we could control from the outside.\nLuckily, according to the source code, viewModelScope is using a Dispatchers.Main.immediate. The main dispatcher can easily be replaced during tests using Dispatchers.setMain. There, we can pass our StandardTestDispatcher.\nHere\u0026rsquo;s how we could set up our test using the @Before and @After annotations:\nprivate lateinit var testScheduler: TestCoroutineScheduler @Before fun setUp() { testScheduler = TestCoroutineScheduler() Dispatchers.setMain(StandardTestDispatcher(testScheduler)) } @After fun tearDown() { Dispatchers.resetMain() } Before each test, we create a StandardTestDispatcher, providing our TestCoroutineScheduler, and set it as the main dispatcher (that we reset after each test).\nThanks to this, the viewModelScope will be using this dispatcher and all coroutines launched on this scope will be sent to our scheduler.\nThe code of our test will be almost identical to the previous one. The only difference is that we don\u0026rsquo;t launch a child coroutine anymore and we control the virtual time by calling methods on the testScheduler variable.\nHere is the full code of our test, including the setup:\nclass ViewModelTest { private lateinit var testScheduler: TestCoroutineScheduler @Before fun setUp() { testScheduler = TestCoroutineScheduler() Dispatchers.setMain(StandardTestDispatcher(testScheduler)) } @After fun tearDown() { Dispatchers.resetMain() } @Test fun `should indicate loading when getting the data`() { // given val viewModel = TasksViewModel(InMemoryTasksRepository()) viewModel.getTasks() // when testScheduler.advanceTimeBy(500) // then assertTrue(viewModel.isLoading.value) // when testScheduler.runCurrent() // then assertFalse(viewModel.isLoading.value) } } Notice that we don\u0026rsquo;t even have to run our test body inside runTest anymore. That\u0026rsquo;s because we are not calling any suspending functions here - getTasks is a regular function.\nSummary I hope this post showed you how we can easily make our tests more powerful and controllable when we write code that uses coroutines.\nI first learned the trick of launching a child coroutine in a test to control it from the outside in a book I highly recommend - Kotlin Coroutines: Deep Dive by Marcin Moskala.\nIf you have any questions, feel free to reach me on Twitter.\n","permalink":"https://arkadiuszchmura.com/posts/how-to-test-intermediate-steps-in-suspending-functions/","summary":"Testing the final result of a suspending function is easy, but what about verifying what happens inside it during the execution?","title":"How to test intermediate steps in suspending functions"},{"content":"Introduction If like me, you have always wondered what is the difference between viewportWidth and width (or viewportHeight and height) in vector drawables and you tend to randomly tweak these attributes until your image looks right, this post is for you.\nI will show you how these attributes differ using a simple example and some visualizations.\nExample To illustrate the difference, I created a simple app with one screen that contains a centered image filling as much content as it needs. Here is the code (in Jetpack Compose):\nclass MainActivity : ComponentActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContent { AppTheme { Box( modifier = Modifier.fillMaxSize(), contentAlignment = Alignment.Center ) { Image( painter = painterResource(id = R.drawable.rectangle), contentDescription = null ) } } } } } And this is the code for the R.drawable.rectangle drawable:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;vector xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:width=\u0026#34;256dp\u0026#34; android:height=\u0026#34;256dp\u0026#34; android:viewportWidth=\u0026#34;36\u0026#34; android:viewportHeight=\u0026#34;36\u0026#34;\u0026gt; \u0026lt;path android:fillColor=\u0026#34;#FFEB3B\u0026#34; android:pathData=\u0026#34;M0,0 L36,0 L36,36 L0,36 z\u0026#34; /\u0026gt; \u0026lt;path android:fillColor=\u0026#34;#3F51B5\u0026#34; android:pathData=\u0026#34;M2,2 L34,2 L34,34 L2,34 z\u0026#34; /\u0026gt; \u0026lt;/vector\u0026gt; If you need a refresher on how to interpret commands like M2,2 in pathData, here is a great post on Ray Wenderlich\u0026rsquo;s blog: link. But to give you a quick overview:\nM2,0 means Move to the point at position 2,0 (x,y). L36,0 means draw a Line from the current point to the point at 36,0 (x,y). z closes the path by drawing a straight line from the current position to the starting point. Remember that 0,0 position is in the upper left corner. Moving to the right increases the X position and moving down increases the Y position (contrary to what you might be used to).\nBoth paths in the drawable above define a rectangle. The first path draws a yellow rectangle that covers the entire available space, while the second path draws a slightly smaller blue rectangle on top of the first one.\nThis is what the rendered image looks like:\nAs you can see, height and width attributes were both set to \u0026ldquo;256dp\u0026rdquo; and viewportWidth, as well as viewportHeight, to \u0026ldquo;36\u0026rdquo;.\nNotice that height and width values end with \u0026ldquo;dp\u0026rdquo;. It\u0026rsquo;s because they define the intrinsic size of the drawable. In simpler words, if you give this drawable to an ImageView that covers as much space as it needs, that ImageView will have the exact same size as the drawable. That\u0026rsquo;s why in the screenshot above, the rendered image has a size of 256dp x 256dp (just like height and width values).\nConversely, viewportWidth and viewportHeight define the canvas size upon which we draw our pixels. All of our commands in pathData use coordinates from this space.\nLet\u0026rsquo;s take a look at the pathData for our blue rectangle:\nandroid:pathData=\u0026#34;M2,2 L34,2 L34,34 L2,34 z\u0026#34; As you can see, all commands here use points that are contained in a space defined by viewportWidth and viewportHeight (which is 36 x 36).\nBelow I marked some of the relevant coordinates:\nNow let\u0026rsquo;s see what happens when I change viewportWidth and viewportHeight to \u0026ldquo;48\u0026rdquo; (and modify the yellow rectangle\u0026rsquo;s pathData to still cover the entire space as in the previous example).\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;vector xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; android:width=\u0026#34;256dp\u0026#34; android:height=\u0026#34;256dp\u0026#34; android:viewportWidth=\u0026#34;48\u0026#34; android:viewportHeight=\u0026#34;48\u0026#34;\u0026gt; \u0026lt;path android:fillColor=\u0026#34;#FFEB3B\u0026#34; android:pathData=\u0026#34;M0,0 L48,0 L48,48 L0,48 z\u0026#34; /\u0026gt; \u0026lt;path android:fillColor=\u0026#34;#3F51B5\u0026#34; android:pathData=\u0026#34;M2,2 L34,2 L34,34 L2,34 z\u0026#34; /\u0026gt; \u0026lt;/vector\u0026gt; Here is the rendered result:\nThe image takes the same amount of space on the screen as before, but the blue rectangle is now smaller. This is because the width and height values stayed the same (\u0026ldquo;256dp\u0026rdquo;), but the coordinate space has changed affecting all of our commands responsible for drawing our paths.\nThis can be better seen in the below image with highlighted points:\nSummary To summarize, the difference between size and viewport size is that the former reports its values (width and height) to the outside world, whereas the latter defines an \u0026ldquo;internal\u0026rdquo; space that is the coordinate space of our pathData.\nIf you are given a vector drawable (or svg) from a designer, remember not to change viewportWidth and viewportHeight attributes. They define the size of the canvas and all pathData commands use this coordinate space. If you change them, your image might become distorted. Instead, if you want to manipulate the image\u0026rsquo;s size, just use width and height.\n","permalink":"https://arkadiuszchmura.com/posts/what-is-the-difference-between-size-and-viewport-size-in-vector-drawables/","summary":"It always puzzled me so I decided to find out how are these things different.","title":"What is the difference between size and viewport size in vector drawables?"},{"content":"Introduction In this post, I would like to show you how you can change the status bar and navigation bar colors using Compose, without having to modify any XML files.\nBefore Jetpack Compose, to specify the bar colors, we would traditionally modify the themes.xml file like this:\n\u0026lt;resources\u0026gt; \u0026lt;style name=\u0026#34;Theme.BarColors\u0026#34; parent=\u0026#34;android:Theme.Material.Light.NoActionBar\u0026#34;\u0026gt; \u0026lt;item name=\u0026#34;android:statusBarColor\u0026#34;\u0026gt;@color/purple_700\u0026lt;/item\u0026gt; \u0026lt;item name=\u0026#34;android:navigationBarColor\u0026#34;\u0026gt;@color/purple_700\u0026lt;/item\u0026gt; \u0026lt;/style\u0026gt; \u0026lt;/resources\u0026gt; As you can guess, the android:statusBarColor and android:navigationBarColor attributes affect the status bar color and navigation bar color, respectively.\nAdditionally, we could specify android:windowLightStatusBar (to make the icons on the status bar dark) or android:windowLightNavigationBar (similarly for navigation bar). Unfortunately, the latter requires API level 27. It forces us to override this attribute in another themes.xml file under the values-27 folder. It can lead to quite a messy structure when we have a lot of attributes like this. It can get even worse when we decide to support a dark theme.\nLuckily, with Compose, there is another way of doing this.\nSolution For this example, I created a simple screen using Compose that displays centered text on a Surface:\nclass MainActivity : ComponentActivity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContent { BarColorsTheme { Surface { Text( modifier = Modifier .fillMaxSize() .wrapContentHeight(), textAlign = TextAlign.Center, style = MaterialTheme.typography.h3, text = \u0026#34;Hello Android!\u0026#34;, ) } } } } } The BarColorsTheme (where BarColors is the name of the app) that wraps everything is a composable function that is created for you when you use the Empty Compose Activity template from the project wizard:\nAndroid Studio\u0026rsquo;s new project wizard\nThis is what it looks like:\nprivate val DarkColorPalette = darkColors( primary = Purple200, primaryVariant = Purple700, secondary = Teal200 ) private val LightColorPalette = lightColors( primary = Purple500, primaryVariant = Purple700, secondary = Teal200 ) @Composable fun BarColorsTheme(darkTheme: Boolean = isSystemInDarkTheme(), content: @Composable () -\u0026gt; Unit) { val colors = if (darkTheme) { DarkColorPalette } else { LightColorPalette } MaterialTheme( colors = colors, typography = Typography, shapes = Shapes, content = content ) } The BarColorsTheme serves as a root composable that specifies the proper color palette (based on whether the dark theme is enabled), typography, and shapes for the entire hierarchy.\nBecause it is a root composable in our app, we can use this place to specify the system bar colors. Here is how we can do that:\n@Composable fun BarColorsTheme(darkTheme: Boolean = isSystemInDarkTheme(), content: @Composable () -\u0026gt; Unit) { // ... val view = LocalView.current if (!view.isInEditMode) { SideEffect { val window = (view.context as Activity).window window.statusBarColor = colors.primary.toArgb() window.navigationBarColor = colors.primary.toArgb() WindowCompat.getInsetsController(window, view) .isAppearanceLightStatusBars = darkTheme WindowCompat.getInsetsController(window, view) .isAppearanceLightNavigationBars = darkTheme } } // ... } We use the window object associated with our activity and modify the appropriate properties - statusBarColor and navigationBarColor. We use a primary color from the current palette (in this case it\u0026rsquo;s a shade of purple).\nAdditionally, we use WindowCompat to make the status bar and navigation bar icons light or dark, depending on the value of the darkTheme variable. A nice benefit of using WindowCompat is that we don\u0026rsquo;t have to check the API level before executing those methods. Behind the scenes, they will have no effect on unsupported APIs.\nAfter making those changes and running the app, we get the desired effect:\nSystem bar colors changed with Compose\nNotice the use of SideEffect here. A SideEffect runs after every recomposition. Thanks to this, the system bar colors will be automatically updated to correct values when a user enables the dark theme, without having to reopen the app:\nSystem bar colors adapting to the current theme\nSummary With Jetpack Compose, specifying system bar colors that adapt to the current theme is quite simple. All of the relevant code sits in one place. We no longer have to create different themes.xml files and override specific attributes.\nI hope you found this post interesting. If you have any questions, feel free to reach me on Twitter.\n","permalink":"https://arkadiuszchmura.com/posts/how-to-change-system-bar-colors-in-compose/","summary":"System bar colors can be changed directly with Compose, without a need to modify any XML files.","title":"How to change system bar colors using Jetpack Compose"},{"content":"Introduction In this post, I would like to write about an interesting concept I learned while reading Designing Data-Intensive Applications by Martin Kleppmann. More specifically, it\u0026rsquo;s a story of how Twitter handled some of its scalability challenges related to users\u0026rsquo; personalized timelines. If you work on an application with some sort of a personalized feed/timeline for each user, the idea introduced here might help you improve the performance or give you inspiration for your next app\u0026rsquo;s architecture.\nScaling timelines In November 2012, at a conference in San Francisco, Raffi Krikorian published some data about two of Twitter\u0026rsquo;s main operations:\nPost tweet - a user can post a new tweet to their followers (4,6k requests/sec on average, over 12k requests/sec at peak). Home timeline - a user can view tweets posted by the people they follow (300k requests/sec). With modern databases, handling 12,000 write requests is achievable fairly easily. But at Twitter, the challenge came not with the volume, but due to so-called fan-out. In transaction processing systems, this term is used to describe the number of requests to other services that need to be made to serve one incoming request. On Twitter, each user follows many people and each user is followed by many people. This means that when a new tweet is published, it needs to be delivered to all of the author\u0026rsquo;s followers. In some cases (e.g. celebrities with many followers), there might be a lot of work to do.\nOn a high level, there are two ways of implementing the two operations mentioned above. Let\u0026rsquo;s examine both of them.\nTraditional approach with relational schema This is probably the first approach that comes to most developers\u0026rsquo; minds. The idea is relatively simple. We need some kind of storage for all posted tweets. When a new tweet is posted, it\u0026rsquo;s simply inserted into this global collection of tweets. When a user opens the website and requests their home timeline, all the tweets from all the people they follow are merged and served on demand. In a traditional relational database, you might have three tables to handle this scenario: users, tweets, and follows.\nusers table id first_name last_name username 21 Arkadiusz Chmura ClouddJr tweets table id user_id content created_at 14 21 Hello World! 2022-03-26 17:46:11 follows table follower_id followee_id 19212 21 Then, to get all the relevant tweets to assemble a user\u0026rsquo;s timeline, the SQL query could look like this:\nSELECT tweets.*, users.* FROM tweets JOIN users ON tweets.user_id = users.id JOIN follows ON follows.followee_id = users.id WHERE follows.follower_id = CURRENT_USER The biggest problem here is that we have to execute the above query every time we want to display a timeline for any user. It\u0026rsquo;s not hard to imagine the huge amount of work required when there are a lot of users on the platform with a substantial number of people they follow frequently accessing the website.\nThe first version of Twitter used this approach, but the system struggled to keep up with the load of home timeline queries. The number of users on the platform kept growing, so they had to introduce another solution.\nMaintaining a cache for individual timelines Here, the basic idea is that we prepare, or cache, each user\u0026rsquo;s home timeline ahead of time so that when it\u0026rsquo;s requested, no additional work is required. When a user posts a tweet, besides being stored in a table, it\u0026rsquo;s immediately inserted into timeline caches for all of their followers. Thanks to this, reading a timeline is very cheap, because it has already been computed - it\u0026rsquo;s enough to just read from the cache. There is no need for any other expensive database operations. This concept is visualized in the image below.\nTwitter\u0026rsquo;s data pipeline for delivering tweets to followers (2012)\nWhen it comes to actual tools that you could use to implement the timeline caching mechanism, a great option would be a very popular, open-source, in-memory data store called Redis.\nHowever, while reading all relevant tweets for each user is very cheap right now, there is one downside of this approach. Posting a tweet now requires a lot of additional work. Besides storing it in a table, it has to be inserted into many other caches. The average number of followers per user is 75, which means 4,6k new tweets per second becomes 345k writes per second to the home timeline caches (4,6k * 75).\nBut the average is affected mainly by users with many followers (there are some with more than 30 million). The majority of users have much fewer followers. This means that the extra work required for the fan-out when posting a new tweet is only noticeable for that small number of users with a very large number of followers.\nFor this reason, Twitter moved to a hybrid approach to take the best of both worlds. Tweets from \u0026ldquo;regular\u0026rdquo; users continue to be fanned-out to timeline caches, as illustrated above, while tweets from celebrities are excepted from that process. When a home timeline is requested, tweets from celebrities are fetched separately from the database and merged with what\u0026rsquo;s inside the user\u0026rsquo;s cache.\nSummary If you found this story interesting, you might enjoy reading the book it was mentioned in - Designing Data-Intensive Applications. It\u0026rsquo;s a good combination of the theory behind many enterprise-level tools and practical engineering. It compares many tools and approaches, including their strengths and weaknesses, to make it easier for us to decide what\u0026rsquo;s best for our applications.\n","permalink":"https://arkadiuszchmura.com/posts/how-twitter-handled-personalized-timelines-for-their-users/","summary":"The approach described here might be useful to you if your application has some sort of a personalized feed for each user.","title":"How Twitter handled personalized timelines for their users"},{"content":"Introduction Spatie created an extremely useful library for working with any type of media in Laravel, called Laravel-medialibrary. It allows you to associate all sorts of files with Eloquent models and organize them into collections. It also has a simple fluent API that makes it effortless and pleasant to use.\nAdditionally, the package supports different filesystems (like Amazon S3) and can manipulate all uploaded images or pdfs according to the specified configuration. It\u0026rsquo;s possible to resize, reformat, apply special effects, and much more. Check out the documentation to learn about everything it can do for you.\nHowever, the feature I like most about this library is that it can automatically create responsive variants of images. The moment you upload an image, the media library will create resized versions of the original image suitable for different screen sizes, as well as a tiny blurred one used for progressive loading (which will be displayed before the full image is ready).\nWhat\u0026rsquo;s even better, the package has support for generating a necessary HTML markup, automatically creating an img tag and specifying src, srcset, and sizes attributes for you.\nTo display your image in a Blade file, all you have to do is output the Media object:\n\u0026lt;h1\u0026gt;My blog post\u0026lt;/h1\u0026gt; {{ $post-\u0026gt;getFirstMedia() }} It\u0026rsquo;s very convenient, isn\u0026rsquo;t it? But what about Vue? In a component\u0026rsquo;s template, we can\u0026rsquo;t just output the object like in a Blade file.\nLuckily, there is a way to make responsive images work in Vue.\nSolution The Media object implements the Htmlable interface, defined as follows:\ninterface Htmlable { /** * Get content as a string of HTML. * * @return string */ public function toHtml(); } Internally, the Blade compiler will use the toHtml() method when it encounters a Media object while rendering the view.\nThis method is public, so nothing stops us from using it ourselves.\nIn a controller that\u0026rsquo;s responsible for providing data used by your Vue component, simply return the result of the toHtml() method:\nnamespace App\\Http\\Controllers; use App\\Http\\Controllers\\Controller; class PostController extends Controller { public function show(Post $post) { return [ \u0026#39;title\u0026#39; =\u0026gt; $post-\u0026gt;title, \u0026#39;content\u0026#39; =\u0026gt; $post-\u0026gt;content, \u0026#39;img\u0026#39; =\u0026gt; $post-\u0026gt;getFirstMedia()-\u0026gt;toHtml() ]; } } Then, inside your Vue component, output the image using the v-html directive by providing the data received from the controller:\n\u0026lt;template\u0026gt; \u0026lt;div v-html=\u0026#34;img\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; And that\u0026rsquo;s it! Now, your image should be correctly displayed based on the screen size.\nSummary If you\u0026rsquo;ve been trying to take advantage of the simplicity of responsive images provided by the media library inside a Vue component, I hope this post saved you some time. If you have some questions, feel free to reach me on Twitter.\n","permalink":"https://arkadiuszchmura.com/posts/how-to-display-responsive-image-from-laravel-medialibrary-in-vue-js/","summary":"It\u0026rsquo;s easy to do in a Blade file, but what about a Vue component?","title":"How to display responsive images from Laravel-medialibrary in Vue.js"},{"content":"Introduction At Google I/O 2017, the Android Framework team introduced Architecture Components - a set of tools that significantly changed how many Android developers write and structure their apps. This post will focus on the internals of one of them - the ViewModel.\nThe ViewModel class is designed to store and manage UI-related data in a lifecycle conscious way. The ViewModel class allows data to survive configuration changes such as screen rotations.\nUsually, one of the first things we find out when learning Android development is that activities get re-created after configuration changes. When it happens, we lose all initialized variables and the view gets re-rendered. We get a completely new activity instance.\nSo when I first heard about the ViewModel class and what it can do, some questions immediately popped up in my head:\nHow is it possible that ViewModels survive configuration changes given that the activities that hold them get destroyed and created again? How does the newly created activity instance access a reference to the same ViewModel used by the previous activity instance? Recently I decided to find answers to those questions. I chose to dive into the Android\u0026rsquo;s source code and explore the ViewModel\u0026rsquo;s implementation details.\nCreating a ViewModel Let\u0026rsquo;s start from the beginning. The recommended approach (at the time of writing this post) to create an instance of a ViewModel class inside an activity is to use the following code:\nprivate val viewModel: MyViewModel by viewModels() where by viewModels() is a syntax representing Kotlin delegated properties.\nThe viewModels() function returns a Lazy\u0026lt;T\u0026gt; instance, which serves as a lazy property delegate. This basically means that a MyViewModel instance is going to be obtained on first access to the viewModel variable (not when this variable is declared).\nHere is what the viewModels() function looks like:\npublic inline fun \u0026lt;reified VM : ViewModel\u0026gt; ComponentActivity.viewModels( noinline factoryProducer: (() -\u0026gt; Factory)? = null ): Lazy\u0026lt;VM\u0026gt; { val factoryPromise = factoryProducer ?: { defaultViewModelProviderFactory } return ViewModelLazy(VM::class, { viewModelStore }, factoryPromise) } It accepts a single parameter - a factoryProducer. If it\u0026rsquo;s specified, the ViewModelProvider.Factory returned by this lambda will be used to create a ViewModel instance. If not, the default one will be used.\nThe function returns an instance of the ViewModelLazy class which is an implementation of the Lazy interface that I mentioned earlier.\nThe ViewModelLazy\u0026rsquo;s constructor takes three parameters. The first one represents a class of the ViewModel we want to create an instance of. The third one is a lambda that returns a ViewModelProvider.Factory. It\u0026rsquo;s the same one as the one passed to the viewModels() function (or a default one).\nThe second parameter is interesting. It\u0026rsquo;s a lambda that returns a ViewModelStore. Here, a lambda is passed that returns a viewModelStore variable. Where is this variable coming from?\nAs you can see, the viewModels() function is an extension function on the ComponentActivity class. So when we call viewModelStore in Kotlin, we effectively invoke the getViewModelStore() method from the ComponentActivity (written in Java) that returns its member variable called mViewModelStore:\npublic ViewModelStore getViewModelStore() { if (getApplication() == null) { throw new IllegalStateException(\u0026#34;Your activity is not yet attached to the \u0026#34; + \u0026#34;Application instance. You can\u0026#39;t request ViewModel before onCreate call.\u0026#34;); } ensureViewModelStore(); return mViewModelStore; } The reason why the ComponentActivity has this method is that it implements the ViewModelStoreOwner interface. This is its declaration:\n/** * A scope that owns {@link ViewModelStore}. * \u0026lt;p\u0026gt; * A responsibility of an implementation of this interface is to retain owned ViewModelStore * during the configuration changes and call {@link ViewModelStore#clear()}, when this scope is * going to be destroyed. * * @see ViewTreeViewModelStoreOwner */ @SuppressWarnings(\u0026#34;WeakerAccess\u0026#34;) public interface ViewModelStoreOwner { /** * Returns owned {@link ViewModelStore} * * @return a {@code ViewModelStore} */ @NonNull ViewModelStore getViewModelStore(); } Now you may ask: \u0026ldquo;What is ViewModelStore?\u0026rdquo;\nAs the name suggests, the ViewModelStore class is responsible for storing instances of ViewModels. This is what this class looks like:\npublic class ViewModelStore { private final HashMap\u0026lt;String, ViewModel\u0026gt; mMap = new HashMap\u0026lt;\u0026gt;(); final void put(String key, ViewModel viewModel) { ViewModel oldViewModel = mMap.put(key, viewModel); if (oldViewModel != null) { oldViewModel.onCleared(); } } final ViewModel get(String key) { return mMap.get(key); } Set\u0026lt;String\u0026gt; keys() { return new HashSet\u0026lt;\u0026gt;(mMap.keySet()); } public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); } } This relatively simple class serves as a wrapper around HashMap\u0026lt;String, ViewModel\u0026gt;. This is the ultimate place where all ViewModels associated with an activity or a fragment are stored.\nNow, since we know what the ViewModelStore is, it\u0026rsquo;s clear what the ViewModelStoreOwner interface is used for. A class that implements it indicates to the outside world that it owns an instance of the ViewModelStore.\nThis is a list of all classes in the Android framework that implement the getViewModelStore() method from the ViewModelStoreOwner interface. Basically, it\u0026rsquo;s only activities and fragments.\nClasses that implement getViewModelStore() from the ViewModelStoreOwner\nLet\u0026rsquo;s look at the documentation from the ViewModelStoreOwner interface, particularly this fragment:\nA responsibility of an implementation of this interface is to retain owned ViewModelStore during the configuration changes and call ViewModelStore#clear(), when this scope is going to be destroyed.\nThis gives us a valuable hint. It means that it\u0026rsquo;s the activity\u0026rsquo;s (or fragment\u0026rsquo;s) responsibility to make sure that its ViewModelStore (along with all ViewModels) is preserved across configuration changes.\nHow do activities handle that? We will come back to this question in the next section.\nFor now, let\u0026rsquo;s go back again to the viewModels() function and see what the newly constructed ViewModelLazy class looks like:\npublic class ViewModelLazy\u0026lt;VM : ViewModel\u0026gt; ( private val viewModelClass: KClass\u0026lt;VM\u0026gt;, private val storeProducer: () -\u0026gt; ViewModelStore, private val factoryProducer: () -\u0026gt; ViewModelProvider.Factory ) : Lazy\u0026lt;VM\u0026gt; { private var cached: VM? = null override val value: VM get() { val viewModel = cached return if (viewModel == null) { val factory = factoryProducer() val store = storeProducer() ViewModelProvider(store, factory).get(viewModelClass.java).also { cached = it } } else { viewModel } } override fun isInitialized(): Boolean = cached != null } Most of the code in this class just deals with caching the object and making sure that the same instance is returned on subsequent calls.\nThe most relevant fragment is this one:\nViewModelProvider(store, factory).get(viewModelClass.java) It creates an instance of the ViewModelProvider class by passing the required parameters (that were created by executing the lambdas passed to the constructor) and calls get() to obtain our ViewModel.\nHere\u0026rsquo;s the get() method:\npublic open operator fun \u0026lt;T : ViewModel\u0026gt; get(modelClass: Class\u0026lt;T\u0026gt;): T { val canonicalName = modelClass.canonicalName ?: throw IllegalArgumentException(\u0026#34;Local and anonymous classes can not be ViewModels\u0026#34;) return get(\u0026#34;$DEFAULT_KEY:$canonicalName\u0026#34;, modelClass) } This methods call another get() method that additionally accepts a key as a parameter. In this case, the key is a concatenated string consisting of two parts separated by a colon:\nA DEFAULT_KEY value (which is \u0026quot;androidx.lifecycle.ViewModelProvider.DefaultKey\u0026quot;). A canonical name of our ViewModel class. This key will be used to identify our ViewModel object in the HashMap\u0026lt;String, ViewModel\u0026gt; that we saw earlier in the ViewModelStore class.\nHere\u0026rsquo;s the second get() method:\npublic open operator fun \u0026lt;T : ViewModel\u0026gt; get(key: String, modelClass: Class\u0026lt;T\u0026gt;): T { var viewModel = store[key] if (modelClass.isInstance(viewModel)) { (factory as? OnRequeryFactory)?.onRequery(viewModel) return viewModel as T } else { @Suppress(\u0026#34;ControlFlowWithEmptyBody\u0026#34;) if (viewModel != null) { // TODO: log a warning. } } viewModel = if (factory is KeyedFactory) { factory.create(key, modelClass) } else { factory.create(modelClass) } store.put(key, viewModel) return viewModel } Without going into too many details, this method basically returns an existing ViewModel specified by the key (if there is one) or creates a new one of the desired type using the provided factory.\nHere we can see the ViewModelStore in action. It\u0026rsquo;s used to get an existing ViewModel instance (var viewModel = store[key]) or to store a newly created one (store.put(key, viewModel)).\nAt this point, we\u0026rsquo;ve finally obtained the ViewModel instance that we wanted. It was either the one we already had access to or a completely new instance.\nOk, we’ve covered a lot of ground. It might be worth pausing for a moment to wrap up what we’ve found so far:\nEvery activity and fragment (from the androidx packages) has a component called ViewModelStore. How do we know it? They declare this fact by implementing the ViewModelStoreOwner interface. The ViewModelStore has references to all ViewModels used by this activity or fragment. This component is preserved across configuration changes. Later in this post, we will see how it\u0026rsquo;s done. When we call private val viewModel: MyViewModel by viewModels() in our activity (or fragment), we create a lazy property delegate that will initialize our ViewModel when we first access the viewModel variable. Internally, the code will create a correct instance and store it in the activity\u0026rsquo;s (or fragment\u0026rsquo;s) ViewModelStore or return the previous instance instead (if there was one). The survival We learned that it\u0026rsquo;s the ViewModelStore that stores our ViewModels. The original question:\nHow ViewModels survive configuration changes?\ncan therefore be rephrased to:\nHow ViewModelStores survive configuration changes?\nLet\u0026rsquo;s focus on activities. Going back to the getViewModelStore() method from the ComponentActivity, we can notice that it calls another method called ensureViewModelStore() before returning its member instance.\nAs a refresher, here\u0026rsquo;s the getViewModelStore() method:\npublic ViewModelStore getViewModelStore() { if (getApplication() == null) { throw new IllegalStateException(\u0026#34;Your activity is not yet attached to the \u0026#34; + \u0026#34;Application instance. You can\u0026#39;t request ViewModel before onCreate call.\u0026#34;); } ensureViewModelStore(); return mViewModelStore; } and this is the ensureViewModelStore():\nvoid ensureViewModelStore() { if (mViewModelStore == null) { NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // Restore the ViewModelStore from NonConfigurationInstances mViewModelStore = nc.viewModelStore; } if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } } } And there we go! It seems that we\u0026rsquo;ve found what we\u0026rsquo;ve been looking for.\nThis method first checks if the mViewModelStore member variable is null. If it is, we restore the previous ViewModelStore (if there is any, otherwise, it creates a new one) using the getLastNonConfigurationInstance() method. This method returns an instance of the NonConfigurationInstances class that\u0026rsquo;s defined as follows:\nstatic final class NonConfigurationInstances { Object custom; ViewModelStore viewModelStore; } As we can see, it has our ViewModelStore object.\nNow we know how our ViewModelStores are restored. There is one final piece of the puzzle to solve. We need to find out how they are saved. Let\u0026rsquo;s start by looking at the documentation of thegetLastNonConfigurationInstance() method:\nRetrieve the non-configuration instance data that was previously returned by onRetainNonConfigurationInstance().\nI think we are getting pretty close. Let\u0026rsquo;s dive into the onRetainNonConfigurationInstance() method. First, this is what the documentation says about it:\nCalled by the system, as part of destroying an activity due to a configuration change, when it is known that a new instance will immediately be created for the new configuration. You can return any object you like here, including the activity instance itself, which can later be retrieved by calling getLastNonConfigurationInstance() in the new activity instance.\nAnd this is what the method looks like in the ComponentActivity:\npublic final Object onRetainNonConfigurationInstance() { // Skipping the irrelevant parts... NonConfigurationInstances nci = new NonConfigurationInstances(); nci.custom = custom; nci.viewModelStore = viewModelStore; return nci; } As you can see, this method prepares the instance of the NonConfigurationInstances class that will be retained across configuration change. It has our current ViewModelStore which means we will be able to successfuly restore it afterwards in the getLastNonConfigurationInstance().\nAnd that\u0026rsquo;s it! All that seems so magical about ViewModels at first glance is just a combination of using this pair of methods from the Activity class:\nonRetainNonConfigurationInstance() getLastNonConfigurationInstance() The process of saving and restoring the ViewModelStore in fragments is very similar. If you are interested, I encourage you to explore the source code to find it out by yourself.\nViewModels and process death Here\u0026rsquo;s one thing worth keeping in mind. As mentioned in the introduction, the ViewModel class allows data to survive configuration changes such as screen rotations, enabling the multi-window mode, etc.\nHowever, the system may destroy your application process while the user is away interacting with other apps. In such a case, the activity instance is destroyed, along with any state stored in it. This is called a process death. ViewModels don\u0026rsquo;t survive a system-initiated process death.\nThis is why you should use ViewModel objects in combination with onSaveInstanceState() or some other disk persistence. To avoid some boilerplate when using the first approach, you might want to take a look at the SavedStateHandle.\nSummary In order to effectively use ViewModels in our Android apps, it\u0026rsquo;s not necessary to entirely understand the details of their implementation. However, many developers are simply curious about how some things work behind the scenes. Knowledge of the internals can make it easier to spot potential edge cases or pitfalls and simplify debugging in the future.\nI hope you learned something new after reading this post and that it satisfied your curiosity. If there are still some parts that you find confusing, feel free to reach me on Twitter and ask some questions. I will do my best to answer them.\n","permalink":"https://arkadiuszchmura.com/posts/how-viewmodels-survive-configuration-changes/","summary":"Let\u0026rsquo;s explore their implementation details to see how they achieve this.","title":"How ViewModels survive configuration changes"},{"content":"Introduction In this post, I\u0026rsquo;d like to write a quick summary of key ideas presented in the book The Pragmatic Programmer written by David Thomas and Andrew Hunt. It will serve me (and you, hopefully) as a reference I can look up later to remind myself of these timeless concepts.\nObviously, it\u0026rsquo;s not possible to cover everything here. I highly recommend reading this book to get a full picture. Here, I focus on things that are in my opinion most important in regards to our everyday work and advancing our careers as programmers.\nThis book is not strictly about code. It\u0026rsquo;s not examining a specific language, tool, framework, or pattern. It\u0026rsquo;s about a philosophy of being pragmatic in our craft. It\u0026rsquo;s aimed at people who want to become more effective and productive programmers.\nThe word pragmatic comes from the Latin pragmaticus, which means “skilled in business”. Let\u0026rsquo;s see what the authors think it means to be a pragmatic programmer.\nTakeaways The ideas listed below are presented in the same order as they appear in the book. The order doesn\u0026rsquo;t imply importance. This means that the last idea is not the least important or useful.\nCraftsmanship Programming is a craft and it\u0026rsquo;s a difficult job. No doubt about it. Every day, we try to transform vague user requirements into a language that computers can understand.\nThe authors compare programmers to craftsmen who employ a set of good-quality tools and can choose the best one for the job at hand. We ought to do the same thing. It\u0026rsquo;s not enough to learn one language and stick with it throughout our entire career. We should aspire to be polyglots that can adapt to the current situation by utilizing the best possible tools to solve the problem.\nIf all you have is a hammer, everything looks like a nail.\nIn an attempt to become pragmatic, we must also ask questions and be curious. How does this library work? Why did you decide to do it this way? Is it the best way to solve this? This will deepen our understanding, broaden our perspective and lead to a feeling of mastery and continuous improvement.\nBe responsible and don\u0026rsquo;t complain Pragmatic programmers aren\u0026rsquo;t afraid to admit ignorance or error. We are humans. A lot of things can go wrong even if we do our best with testing, documentation, or automation. The question is not if it happens, but when. It\u0026rsquo;s unavoidable.\nThe best we can do then is to acknowledge the problem, take responsibility for it, and try to offer options to fix it. Unfortunately, what we usually do instead is complain. We blame someone or something else - coworkers, programming languages, tools, etc.\nImagine that it wasn\u0026rsquo;t our code that introduced the error, but someone else\u0026rsquo;s. It doesn\u0026rsquo;t matter. We all work towards the same goal. If we help our teammates, they will do the same thing for us later. This builds a healthy relationship in the team. Others will also remember that you can be trusted.\nSuggest options. Don\u0026rsquo;t make excuses.\nBefore I approach anyone and tell them why something can\u0026rsquo;t be done or that it\u0026rsquo;s not my fault, I stop and listen to myself. How does this excuse sound? What will they think of me?\nI try to position myself in their shoes. How do I react when someone (such as an auto mechanic) comes to me with a lame excuse? What do I think of them or their company after that?\nDon\u0026rsquo;t accept any broken window The authors describe a phenomenon of cities where some buildings are in perfectly well shape while others have gone really bad. Researchers discovered that there exists a trigger mechanism that can quickly turn a beautiful and clean building into an abandoned derelict.\nWhat is that trigger? A broken window.\nHere is what they found:\nOne broken window, left unrepaired for any substantial length of time, instills in the inhabitants of the building a sense of abandonment—a sense that the powers don’t care about the building. So another window gets broken. People start littering. Graffiti appears. Serious structural damage begins. [\u0026hellip;]\nIn my opinion, this analogy suits software quite well. I\u0026rsquo;m sure we\u0026rsquo;ve all seen codebases that were doing just fine only to find later that they are slowly descending to a ruin.\nA broken window could be any shortcut that we\u0026rsquo;ve taken to make things easier for us at the moment. A broken design or architecture, wrong decision, poor or dirty code.\nIf we allow a single broken window in our codebase, we can be sure that there will be more to come.\nYour growth is your responsibility We all know we should stay on top of technologies and the latest trends and constantly keep learning. I think no one has to be convinced about this anymore.\nWhat I like about this book is that it gives us some very specific guidelines for building our knowledge portfolio that we can take inspiration from:\nLearn at least one new language every year. You\u0026rsquo;ll learn several different approaches to solving various problems. It\u0026rsquo;ll broaden your thinking. Read a technical book each month. A book will give you the depth that you won\u0026rsquo;t find in podcasts, blog posts, or online videos. Take classes or workshops. Look for occasions to expand your knowledge. Participate in local user groups or meetups. Don\u0026rsquo;t just go and listen. Participate actively. Experiment with different environments. For example, if you\u0026rsquo;ve only worked with IDE, consider spending some time with a text editor, and vice versa. Stay current. Follow interesting people in your field, read blogs, make side-projects. Easier To Change Programmers often like to argue and discuss which framework, language, or design pattern is the best.\nWhen we learn to program, we are taught about different rules or principles that we are supposed to follow. YAGNI (You Aren\u0026rsquo;t Gonna Need It), DRY (Don\u0026rsquo;t Repeat Yourself), KISS (Keep It Simple, Stupid) the Law of Demeter, and a whole bunch of others.\nAuthors argue that at the end of the day, what really matters is that the system we are working on is Easier To Change (ETC).\nWhy should we favor composition over inheritance? Because it makes things easier to change.\nWhy is decoupling useful? Because by isolating concerns we make them easier to change.\nWhy do we always make sure to follow the Single Responsibility rule? Because if there is a change in the requirements, we only have to touch a single module. ETC.\nETC is a value, not a rule, that should help you make decisions. By asking whether the approach I\u0026rsquo;m taking will make it relatively easy to change it later when needed, you will usually know which path to choose.\nPrototypes and Tracer Bullets One of the ideas behind prototyping is that you will throw away every piece of code you wrote to explore or try the concept.\nFor example, to prove that your idea is doable, you could start with a more forgiving language like Python. At this point, you don\u0026rsquo;t need any user interface, specific architecture, or design. None of the code will end up in the codebase anyway.\nWhen you verify that your vision is indeed possible to implement, you ditch everything and recode it properly using the lessons you\u0026rsquo;ve learned and tools that work on your target\u0026rsquo;s platform.\nOn the other spectrum, we have tracer bullets. Authors use the term tracer bullet development to visually illustrate the need for immediate feedback under actual conditions with a moving goal.\nIt\u0026rsquo;s an important distinction. With the tracer bullets approach, you don\u0026rsquo;t throw away any code when you finish. The code you write will end up in the final product. The only difference is that you focus on the key aspects of the system first.\nFor instance, imagine building a mobile application where users fill out a form. That submission hits our server to be processed later. A finished app requires a pleasant user interface with animations, validation on both the client and server-side, well-formatted responses, etc.\nWith the tracer bullet development approach, we would first focus on the most important things. We would start with a very basic form without any validation, and the submission would be printed to the console or saved in logs on the server-side without hitting the database.\nAt this point, we have a solid foundation. We\u0026rsquo;ve established the communication between the mobile app and our server. The code is covered by tests. Now, we have something to show to our clients or teammates. Later, we can expand and add more functionality with confidence.\nEstimating time Managers or clients often ask us to evaluate how long something will take. Estimating time is extremely difficult, especially when people expect us to provide a single number, like 12 days.\nIn the real world, people don\u0026rsquo;t estimate with single numbers. They use a range of scenarios.\nThere is a methodology that adopts this style of assessment. It\u0026rsquo;s called Program Evaluation Review Technique, or PERT.\nEvery PERT task has an optimistic, most likely, and pessimistic estimate. The tasks are arranged into a dependency network, and then you use some simple statistics to identify likely best and worst times for the overall project.\nWith this approach, you don\u0026rsquo;t specify one fixed number. It helps to account for different potential problems that we might encounter along the way.\nOf course, a single method won\u0026rsquo;t suddenly make estimating easy. That\u0026rsquo;s why it\u0026rsquo;s important to record our estimates. When we finish a project or an iteration, we can see how close we were. If the gap was significant, we should stop and think about a reason. With time and practice, we will give more accurate estimations.\nBe fluent with your tools If you recall yourself trying to learn how to drive a car, you might remember that you had to think about every action you took. Later, with more experience, controlling the car became automatic and instinctive.\nWe should aim for the same automation mechanisms when using our tools. If we don\u0026rsquo;t have to think about all the keyboard shortcuts and options while programming, our minds will have more capacity to think about the problem at hand.\nThe authors give us some tips about what it means to be fluent with our tools. You are fluent when you can:\nWhen editing text, move and make selections by character, word, line, and paragraph. When editing code, move by various syntactic units (matching delimiters, functions, modules, etc.). Reindent code following changes. Comment and uncomment blocks of code with a single command. Split the editor window into multiple panels and navigate between them. Navigate to a particular line number. Search for both strings and regular expressions. Temporarily create multiple cursors based on a selection or a pattern match, and edit the text at each in parallel. Run the current project’s tests. Ideally, you can do all of this without using a mouse or a trackpad.\nDebug with confidence Debugging and finding errors is not always fun. There is no point in making it more problematic than it has to be. The authors give us some general steps that we can follow to make this process at least a bit more effortless for us.\nFirst, before you start debugging, you should adopt the right mindset. Turn off all defensive mechanisms that protect your ego. Also, don\u0026rsquo;t waste time thinking that this couldn\u0026rsquo;t happen or it was impossible. You are looking at the stack trace right now. It clearly did happen.\nThen, always begin with making a bug reproducible. If you can\u0026rsquo;t do it, you will never know if it\u0026rsquo;s fixed. Ideally, try to make it possible to reproduce the error with a single command or action.\nThe root of the problem may lie in the OS, the compiler, or a third-party library. But that should never be your first thought. Always assume that the bug exists in your code and start from there. Because even if it does lie in the library, you would still have to trace the problem in your code before submitting the bug report to the maintainers.\nLastly, make sure that whatever was the problem, you’ll know if it occurs again. If your tests pass with the bug in the code, you can\u0026rsquo;t trust them with catching the bug next time.\nWrite a test, see it fail, fix the bug, and sleep well knowing that you are covered.\nEngineering daybook Have you ever found yourself trying to remember how you solved a particular problem? You probably wished at that moment that you had written the solution and explanation somewhere. It would save you a lot of time and energy.\nThat\u0026rsquo;s why Andy and Dave recommend keeping an engineering daybook when working. It\u0026rsquo;s a kind of journal in which you record what you do, things you learned, sketches of ideas, notes from meetings, variable values when debugging, etc.\nThe daybook has many benefits:\nIt\u0026rsquo;s more reliable than memory. It acts as a kind of rubber duck. It forces you to think about a problem before writing it down. It serves as a database of documented memories. You can look at it and think about the people you collaborated with, projects you worked on, and problems you faced. The authors suggest sticking to a plain old pen and paper. However, I think it might make sense to use a digital version for one reason. It\u0026rsquo;s searchable, and you can categorize your notes more easily.\nDead programs don\u0026rsquo;t lie Programmers tend to take a defensive approach when programming. We try to catch or rescue all possible exceptions, check for nullability before using variables, verify that the lists passed as arguments are not empty, etc. We avoid crashes at all costs.\nThe problem with this approach is that the app or system we are working on might stop working silently on production without us having any way of detecting it.\nSure, we checked that the list we wanted to display on the screen wasn\u0026rsquo;t empty or null. There will be no exception thrown when we try to access it. But what will the user see? Most likely a blank screen. Our app will be in a state that it wasn\u0026rsquo;t designed for. At this point, it\u0026rsquo;s hard to tell why the list was empty. Did we forget to populate it? Did we receive corrupted data from the backend?\nIf our app gets in a weird state, it would be nice to know it. That\u0026rsquo;s why unhandled exceptions are not always such a bad thing. They are collected by your crash reporting tool and will help you find the root of the problem.\nAdditionally, allowing our program to continue after entering an inappropriate state might be disastrous. Anything it does from this point forward can introduce strange problems like inconsistent or corrupted data sent to our production database.\nA dead program does a lot less damage than a crippled one.\nI also recommend reading this article (and its comment section for contrasting opinions) about crashes in mobile apps.\nTake small steps It\u0026rsquo;s usually better to take small and deliberate steps. You then check for feedback and adjust before proceeding. Feedback can take many forms, for example, an MVP that you show to your client or unit tests that verify the correctness of your last code change.\nWe should avoid steps that are too big. They require an attempt to predict the future. No one can do that. You might want to think twice when you find yourself doing one of those things:\nEstimate completion dates months in advance. Guess users\u0026rsquo; future needs and preferences. Predict future tech trends and tools. Around two decades ago, debates raged in online forums over questions like \u0026ldquo;Who would win the desktop GUI wars, Motif or OpenLook?\u0026rdquo;. Chances are, you\u0026rsquo;ve never heard of these technologies. Remember this story next time you see yourself fortune-telling.\nDecoupling We want our code to be as flexible as possible. Coupled code is hard to change. Modifications in one place can have secondary effects in other locations.\nThe authors present this snippet of code to demonstrate the problem:\nprivate fun applyDiscount(customer: Customer, orderId: Int, discount: Discount) { customer .orders .find(orderId) .getTotals() .applyDiscount(discount) } What we can see here is the so-called Train Wreck. This code is traversing five levels of abstraction, from customer to total amounts. Our top-level code has to know about each level\u0026rsquo;s internal implementation. It knows that the customer object exposes orders, that the orders have a find method, and that the order object has a totals object which contains information about discounts and grand totals.\nThere is a lot of coupling here. Imagine that someone decides that no order can have a discount of more than 50%. Where should we implement this change? You might think that it belongs to applyDiscount(). It\u0026rsquo;s true, but the problem is that there might be other places that modify the totals object besides this function. We would have to find all of them and adjust accordingly. That\u0026rsquo;s potentially a lot of work.\nSo, what\u0026rsquo;s the solution? Andy and Dave have a principle that they call:\nTell, Don\u0026rsquo;t Ask.\nWe shouldn\u0026rsquo;t ask about an object\u0026rsquo;s internal state and then modify it based on the information we receive. We should tell it to do what we need.\nWe could refactor the code above to something like this:\nprivate fun applyDiscount(customer: Customer, orderId: Int, discount: Discount) { customer .findOrder(orderId) .applyDiscount(discount) } With this change, our top-level code doesn\u0026rsquo;t have to know that the order class uses a separate object to store its totals and discounts. We also don\u0026rsquo;t fetch a list of orders from the customer and search for a specific one. We get the order that we want directly from the customer.\nRight now, we have only one place that manages discounts and all rules can be encapsulated there.\nFear of the blank page I\u0026rsquo;m sure we\u0026rsquo;ve all experienced this. We start working on a new feature or a completely new project. The cursor is blinking. The screen is empty and ready to be filled with code. For some reason, the experience is very intimidating. We put off making the initial commitment of starting.\nThe authors say the most likely reason we feel this way is that we are afraid of making a mistake. We fear the architecture we are implementing will not be flexible enough. We worry that the code will not be readable by other developers. We stress about introducing new bugs or problems. Potentially, we may think that the task is beyond our skills. We can\u0026rsquo;t see our way through to the end.\nAndy and Dave claim that they found a brain hack that seems to work in this kind of situation:\nPretend that you are prototyping.\nRemember that prototypes get thrown away, even if they don\u0026rsquo;t fail. If your mind knows this, you are less likely to feel anxious. If anything goes wrong, you will stash all of it away. No problem. But what\u0026rsquo;s usually happening is this. After some time, you find that the code flies from your brain into the editor. The initial stress is gone. You start to see the bigger picture. You know how to proceed.\nTo make it even more clear to you, the authors suggest writing \u0026ldquo;I\u0026rsquo;m prototyping\u0026rdquo; on a sticky note and attaching it on the side of your screen.\nI tried this trick a couple of times and it worked for me. It helps with one of the hardest things - forcing yourself to start writing.\nDon\u0026rsquo;t program by coincidence When you use a technology you don\u0026rsquo;t understand, you program by coincidence. If you\u0026rsquo;re unsure why something works, you won\u0026rsquo;t know why it fails. Programming by coincidence is the opposite of programming deliberately.\n\u0026ldquo;It doesn\u0026rsquo;t work without it\u0026rdquo; is not a good reason to keep maintaining a specific portion of code. Unnecessary calls slow the program down or introduce bugs that are difficult to spot. What\u0026rsquo;s worse is that other developers won\u0026rsquo;t usually bother trying to mess with it to improve it. \u0026ldquo;If it works now, it\u0026rsquo;s better to leave it alone\u0026hellip;\u0026rdquo;\nWe all want to work with error-free code and catch all bugs as early in the development cycle as possible. To do that, we should always program deliberately. Make sure you have at least a basic understanding of all the libraries and tools you use in your application or system. Asks yourself questions - would I be able to explain this piece of code to a more junior programmer? If not, perhaps you are relying on coincidence.\nNext time something seems to work, but you don’t know why, make sure it isn’t just a coincidence. Don\u0026rsquo;t assume anything. Prove it.\nCode is a garden A tourist visiting England’s Eton College asked the gardener how he got the lawns so perfect. “That’s easy,” he replied, “You just brush off the dew every morning, mow them every other day, and roll them once a week.”\n“Is that all?” asked the tourist. “Absolutely,” replied the gardener. “Do that for 500 years and you’ll have a nice lawn, too.”\nCode is not static. It constantly evolves. Inaccurately, some people associate software development with building construction. It implies that there is an architect that draws the initial blueprints. Then, contractors dig the foundation, build the superstructure and apply final touches. At this point, there is no easy way to change anything. The project is considered finished and the tenants move in.\nThe software doesn\u0026rsquo;t quite work that way. It\u0026rsquo;s more like a garden when things change all the time. You plant different things according to the initial plan and environment. After observing the typical weather conditions, you may move plantings to other places. Overgrown plants get split. You pull weeds and fertilize plantings. The health of the garden needs constant monitoring and adjustments.\nThe gardening metaphor is much closer to the realities of software development. Laws of physics don\u0026rsquo;t constrain code as they do with buildings.\nThis philosophy led to a discipline called Refactoring. Martin Fowler defines it as a \u0026ldquo;disciplined technique for restructuring an existing body of code, altering its internal structure without changing its external behavior.\u0026rdquo; This technique inlines with the idea that code requires constant improvement and refinement.\nTests aren\u0026rsquo;t only about finding errors When we ask developers why they write tests, most of them would say \u0026ldquo;to make sure the code works\u0026rdquo;. It\u0026rsquo;s a perfectly valid reason. But Andy and Dave argue that there is much more to tests than that.\nThey believe that the sole act of thinking about tests while coding is the main benefit of tests.\nConsider the following example. You are working on a class that is supposed to fetch tomorrow\u0026rsquo;s lottery numbers. That\u0026rsquo;s the code you have written so far:\nclass FetchTomorrowsLotteryNumbersUseCase { private val service = LotteryNumbersService() operator fun invoke() = service.fetch() } The above code works completely fine when you run it. Now what\u0026rsquo;s left is to wait for tomorrow and hope that this service is reliable.\nBut because you are constantly thinking about tests, you start wondering how to write tests for the given code. It would be reasonable to use some test data and not rely on the remote service. The current implementation makes it problematic because we don\u0026rsquo;t control how this class interacts with data. The easiest way to make it possible during tests is to pass the service as a parameter. The code could now look like this:\nclass FetchTomorrowsLotteryNumbersUseCase( private val service: LotteryNumbersService ) { operator fun invoke() = service.fetch() } Thinking about testing made us reduce coupling in the code (by passing in a service that we can control from the outside) and increase flexibility. When we think about writing tests for the code we are working on, we imagine ourselves as clients of the code, not its authors.\nBe proud of your work The authors say that pragmatic programmers should be proud to sign their work just like artisans of an earlier age. When we are accountable for a piece of code, we aspire to do a job we can be proud of.\nThe opposite of it is anonymity. It provides room for mistakes, sloppiness, and bad code, especially on large projects. It creates an environment where no one feels any responsibility.\nWe should aim to associate our signatures with an indication of high quality. When other developers see our code, they should expect it to be solid, well-written, thoroughly tested, and documented.\nSummary Andy and Dave end the book by concluding that we have a lot of power (and responsibility) as programmers. Systems and devices that we build can shape the lives of millions. How often do we stop and think about this?\nWe should do our best to protect the users from any potential harm. If we are involved in a project that requires us to do something against our beliefs or values, we shouldn\u0026rsquo;t be afraid to say \u0026ldquo;no\u0026rdquo;. Would I enjoy using this software as a user? Would I be comfortable with my sensitive data being shared with this company? Do I know something important that users don\u0026rsquo;t?\nWe are building the future for ourselves and our descendants. Let\u0026rsquo;s envision the future everyone would like to live in and have the courage to work on it every day.\n","permalink":"https://arkadiuszchmura.com/posts/my-key-takeaways-from-the-pragmatic-programmer/","summary":"In this blog post, I list things that resonate with me most after reading this book.","title":"My key takeaways from The Pragmatic Programmer"},{"content":"Introduction When creating a widget for your Android app, one of the components that you need to define is a class that extends AppWidgetProvider. Through it, you will receive broadcasts when the widget is updated, enabled, disabled, deleted, resized, etc. You can then act accordingly and, for example, refresh the widget\u0026rsquo;s view to display the newest data.\nI implemented a widget in one of my apps following the steps mentioned in the documentation and everything was working just fine.\nAt least until one day. After noticing that my app is getting bigger, I decided to change the structure of my app a little to package classes by features rather than by layers.\nWhen I changed the package name of my class extending AppWidgetProvider from\ncom.arkadiusz.Provider.MyAppWidgetProvider to\ncom.arkadiusz.data.providers.MyAppWidgetProvider and relaunched the app, all app\u0026rsquo;s widgets disappeared from my home screen.\nI can consider myself lucky for noticing this before releasing the next version of the app and causing this problem for all users.\nIt is quite strange that changing a package name of one class can produce such a radical effect so let\u0026rsquo;s dive into the Android source code and find out why this is happening.\nBehind the scenes In Android, a system service responsible for managing widgets across the entire OS is called AppWidgetService. This is a component that knows, among other things, how and when to update your widgets (based, for example, on the information that you specify in your AppWidgetProviderInfo XML).\nInternally, some of the variables that it holds are as follows:\nprivate final ArrayList\u0026lt;Widget\u0026gt; mWidgets = new ArrayList\u0026lt;\u0026gt;(); private final ArrayList\u0026lt;Host\u0026gt; mHosts = new ArrayList\u0026lt;\u0026gt;(); private final ArrayList\u0026lt;Provider\u0026gt; mProviders = new ArrayList\u0026lt;\u0026gt;(); mWidgets stores references to all widgets that are placed within all hosts. mHosts stores references to all AppWidgetHosts, which are components designed to be used by applications that want to embed widgets in their UI (mostly home screen applications). They provide interaction with the AppWidget service. mProviders stores references to all AppWidgetProviders that were registered by currently installed apps. Each Provider object is identified by a ComponentName (which stores two pieces of information - package name and the class name). It also keeps references to all widgets that it is responsible for. The AppWidget service also listens for different broadcasts related to application packages (like Intent.ACTION_PACKAGE_ADDED or Intent.ACTION_PACKAGE_REMOVED). It does that to keep its ArrayLists up to date. For example, when a user deletes an app from their device, the service can remove every widget and provider associated with this app because they are no longer needed.\nI mentioned earlier that the service identifies each provider by its ComponentName. Well, if we decide to change the provider\u0026rsquo;s package name or class name, the new ComponentName is going to be different. This is the root of the problem.\nHere is what happens when you modify your provider\u0026rsquo;s package name or class name and then update your app:\nThe AppWidget service is notified about an application package update via a broadcast. It reads the app\u0026rsquo;s manifest file and finds a new provider that it hasn\u0026rsquo;t seen before (it has a unique ComponentName). It registers and stores it inside the mProviders variable. Then, the service notices that it keeps a reference to a provider that is no longer used (your previous provider). There is no manifest file that declares it so the service decides that it is safe to remove it entirely. As part of the provider\u0026rsquo;s removal process, every widget associated with that provider is removed as well. You end up with empty widgets on the home screen that are no longer referenced by any component and cannot be updated. The only way to get them to work again is to add them to the launcher anew. I am not alone Interestingly, developers working on the Firefox app faced the same problem. If you look at the source code of their class extending AppWidgetProvider, you will find a comment at the top warning against modifying the package name or the class name:\nclass SearchWidgetProvider : AppWidgetProvider() { // Implementation note: // This class name (SearchWidgetProvider) and package name (org.mozilla.gecko.search) should // not be changed because otherwise this widget will disappear from the home screen of the user. // The existing name replicates the name and package we used in Fennec. Solution? Unfortunately, there is currently no way to solve this problem as the code responsible for this behavior lies beyond our control. The only thing you can do is to make sure not to modify anything related to your widget provider after releasing your app if you don\u0026rsquo;t want your users to lose their existing widgets.\nHonestly, in most cases, it won\u0026rsquo;t be a huge deal. Even though users would have to place those widgets again on their home screen, everything will continue to work as previously. However, if the configuration of widgets in your app is complicated and time-consuming, this can cause a lot of frustration.\nSummary Once you implement widgets in your app and release it, do not change the package name or class name of your class extending AppWidgetProvider. It will wipe out all of your user\u0026rsquo;s existing widgets and possibly bring a flood of 1-star reviews for your app.\n","permalink":"https://arkadiuszchmura.com/posts/do-not-change-the-package-name-or-class-name-of-your-app-widget-provider/","summary":"If you do this, widgets that were placed on the home screen by your users will simply disappear.","title":"Do not change the package name or class name of your AppWidgetProvider"},{"content":"Introduction Users of one of my apps heavily rely on widgets. They place them on their home screens to count days to specific events. It is therefore important to keep those widgets up to date and refresh them at least once per day.\nNot long ago, I have been getting some emails (as well as 1-star reviews) from my users reporting that their widgets are not being updated properly on their phones.\nThe Android documentation says that to update a widget periodically at some interval, you can specify android:updatePeriodMillis attribute on the widget\u0026rsquo;s metadata - AppWidgetProviderInfo XML.\nUnfortunately, despite setting this attribute in my app, widgets were still not updated reliably on some users\u0026rsquo; phones.\nThe problem might be that some vendors introduce their own set of rules that restrict background processing and ignore this attribute altogether under some circumstances to artificially save some battery life.\nSolution Since I could not count on this attribute alone, I needed another solution to support it. Luckily, Android Jetpack has a component that could help me periodically update widgets - WorkManager. As of writing this article, it is the primary recommended API for background processing.\nQuoting the documentation, WorkManager handles three types of persistent work:\nImmediate: Tasks that must begin immediately and complete soon. May be expedited. Long Running: Tasks which might run for longer, potentially longer than 10 minutes. Deferrable: Scheduled tasks that start at a later time and can run periodically. Support for the third type of work perfectly matched my use case so I decided to give it a try.\nHere are the steps I took to import and setup WorkManager in my app:\n1. Import the library into your Android project (using the newest version):\ndependencies { val work_version = \u0026#34;2.7.1\u0026#34; // Java only implementation(\u0026#34;androidx.work:work-runtime:$work_version\u0026#34;) // Kotlin + coroutines implementation(\u0026#34;androidx.work:work-runtime-ktx:$work_version\u0026#34;) } 2. Define the work\nHere we specify what our work actually does. We do this by creating our own implementation of the Worker class and overriding the doWork() method. This method runs asynchronously on a background thread provided by WorkManager.\nIn this case, we simply grab a list of relevant widget ids and notify the AppWidgetManager to perform an update on them by sending an Intent.\nclass WidgetUpdateWorker( private val appContext: Context, workerParams: WorkerParameters ) : Worker(appContext, workerParams) { override fun doWork(): Result { // This line might be different in your case val widgetIds = DatabaseRepository.getWidgetIds() val intent = Intent( AppWidgetManager.ACTION_APPWIDGET_UPDATE, null, appContext, MyAppWidgetProvider::class.java ) intent.putExtra(AppWidgetManager.EXTRA_APPWIDGET_IDS, widgetIds) appContext.sendBroadcast(intent) return Result.success() } } One thing to note here - MyAppWidgetProvider is a subclass of the AppWidgetProvider that is needed when creating a widget.\n3. Define WorkRequest and schedule it\nNow that we defined our work, it is necessary to specify how and when that work should be run. We do this by defining a WorkRequest. In our case, we simply want to run the work periodically at some interval.\nval widgetUpdateRequest = PeriodicWorkRequestBuilder\u0026lt;WidgetUpdateWorker\u0026gt;( 4, TimeUnit.HOURS ).build() Finally, we can put everything together and schedule our work. The code below could be placed in the Application.onCreate() or in your main activity\u0026rsquo;s onCreate().\nWorkManager.getInstance(this).enqueueUniquePeriodicWork( \u0026#34;widgetUpdateWork\u0026#34;, ExistingPeriodicWorkPolicy.KEEP, widgetUpdateRequest ) The first parameter - \u0026quot;widgetUpdateWork\u0026quot; is a unique name that identifies the work.\nThe ExistingPeriodicWorkPolicy.KEEP flag tells the WorkManager to keep using the existing work if there is one already scheduled with the same name.\nThe third parameter is a WorkRequest that we\u0026rsquo;ve just defined.\nAnd that\u0026rsquo;s it! The work is now scheduled and our widgets are going to be periodically updated.\nAs a side note, there are many benefits to using the WorkManager versus relying on the standard way of updating the widgets. Here are some of them:\nOnce you specify the android:updatePeriodMillis attribute, it is fixed and cannot be changed in any other way than updating the app with a new value. On the other hand, you can let your users decide how often widgets should be updated with WorkManager and change this value at runtime. WorkManager automatically ensures that the scheduled tasks are going to finish even when the OS decides to kill the app to reclaim some memory. Internally, WorkManager uses JobScheduler (on API 23+) or a combination of AlarmManager and BroadcastReceiver on older versions. This makes it less likely to be restricted by some vendors. After introducing WorkManager, the number of emails from my users about their widgets not being updated properly dropped significantly.\nSummary To summarize, here are the key points from this post:\nSome vendors restrict background processing in order to save some battery life. Because of this, the standard way of updating widgets (with the android:updatePeriodMillis attribute) doesn\u0026rsquo;t always work. To solve this problem, we can introduce WorkManager that will periodically update widgets and make sure that they are up to date. ","permalink":"https://arkadiuszchmura.com/posts/how-to-reliably-update-widgets-on-android/","summary":"The default solution with android:updatePeriodMillis doesn\u0026rsquo;t always work.","title":"How to reliably update widgets on Android"},{"content":"Introduction In December 2021 I was working on a problem from the Advent of Code 2021 that required getting all elements from two collections that were contained in both of them. In Kotlin, there is an extension function for that use case on Iterable called intersect.\nIn my case, the first collection was a regular List and the second one was a Set.\nThe code that I eventually used was analogical to this one:\nval x = (1..1_000_000).toList() val y = (1..100_000).toSet() x intersect y However, when refactoring the code, I incidentally changed the order of the operands and the last line became y intersect x.\nGiven the fact it was the only modification to the code I made, I was genuinely surprised to find that my program now runs a couple of times slower.\nThat led me to run some experiments to verify whether this seemingly irrelevant change really affects the performance such drastically or the reason was to be found somewhere else.\nThe experiment I decided to use the same code introduced above and measure the execution time separately for both variants:\nFor x intersect y. For y intersect x. For each variant, the experiment was repeated 20 times on my machine (MacBook Pro 13-inch, early 2015) and the average time was obtained.\nFull code for the experiment:\nval results = mutableListOf\u0026lt;Long\u0026gt;() repeat(20) { measureTime { val x = (1..1_000_000).toList() val y = (1..100_000).toSet() x intersect y // or y intersect x }.inWholeMilliseconds.also { results.add(it) } } print(results.average()) Here are the results:\nVariant Time x intersect y 224 ms y intersect x 4793 ms As you can see, the outcome is quite surprising. What\u0026rsquo;s more, the bigger the y collection, the greater the time difference between those two variants.\nFindings Overall, as I dig deeper into the topic (including the source code of the intersect function), I realized that the problem is not the order of the operands itself, but rather the fact that the second operand in the slower variant was not of type Set.\nMoreover, this problem only exists starting with Kotlin 1.6. In prior versions, both of those tested variants (x intersect y and y intersect x) would yield the same results. That\u0026rsquo;s why it might be worth providing a little story behind this issue:\nBefore Kotlin 1.6 In many cases, when running some of the Collection operations (such as aforementioned intersect, minus, removeAll or retainAll), Kotlin tried to optimize them by converting their second operands to a Set under the hood.\nWhy would it do that?\nLet\u0026rsquo;s consider the minus operation. It returns a list consisting of elements from the first collection that are not present in the second collection. It does that by filtering the first collection to keep only the items that are not in the second collection. But how does it know that a specific item is not present in that collection? By calling its contains method.\nTypically, the complexity of checking for the existence of an item in a regular list or array is linear. We have to go through each item one by one. On the other hand, that complexity is reduced to a constant time for sets. To check whether an item is present in the set, it is enough to compute its hash code.\nFor that specific reason, Kotlin tried to introduce this optimization any time it could to improve the performance. But it was not possible in all cases.\nThe problem was that a collection could override its contains method causing some unexpected behavior down the road.\nFor instance, imagine we pass a collection with overridden contains method that we count on (for example, an IdentitySet). Kotlin then converts it under the hood to a different type - a HashSet. With this change, we can no longer rely on our custom contains implementation because the initial collection is now of another type. This could lead to some errors that are difficult to debug.\nThat is why the optimization was applied only in specific cases:\nWhen the operand was not implementing a Collection interface (meaning it could not override its contains method). When the operand is a known implementation of Collection that doesn\u0026rsquo;t override contains (currently only kotlin.collections.ArrayList) However, as it turned out, this optimization was quite problematic for a few reasons:\nThe code responsible for deciding whether to convert the second operand to a Set was quite difficult to read. Therefore, it was not obvious at the first glance if it was going to be converted or not. Sometimes, we might not be aware of the actual implementation of a specific collection - it could be \u0026ldquo;hidden\u0026rdquo; behind some interface. So, we cannot easily deduce whether it would get converted or not. There were some problems (described here) leading to incorrect results when any element changed its hashCode value after being placed to the converted set. Since Kotlin 1.6 For the reasons mentioned above, the Kotlin team decided to remove this optimization entirely. Now, the second operand will never be converted to a Set. At most, it will be converted to a List if the operand is not implementing the Collection interface.\nFor a full list of affected API, see this link.\nBecause this decision could potentially cause performance degradation in some cases, an inspection was added to inform about this issue offering an option to manually convert the second operand to a Set.\nInspection in IntelliJ IDEA informing about a potential performance issue.(The argument can be converted to \u0026lsquo;Set\u0026rsquo; to improve performance)\nFor now, it is possible to enable this optimization back on the JVM with a system property (kotlin.collections.convert_arg_to_set_in_removeAll). This will give more time to the developers that were previously relying on this feature to migrate the affected code.\nAlthough, it is worth mentioning that the possibility of enabling the optimization back is planned to be removed in Kotlin 1.7. The same thing is going to happen to the inspection. It will be turned off by default with the next major release. Yet you will be able to turn it on again by going to Preferences -\u0026gt; Editor -\u0026gt; Inspections -\u0026gt; Kotlin -\u0026gt; Other problems.\nThey give the following explanation for their decision:\nHowever, we expect this inspection to be quite annoying in places where such time complexity does not that matter, so we plan to disabling it by default in the next version of Kotlin and leaving only an intention.\nSummary To summarize, here are the key points from this post:\nSince Kotlin 1.6, the second operands of some Kotlin Collection operations will no longer be converted to a Set under the hood. That may have some performance implications, so an inspection was added to inform you about this issue whenever applicable. However, the inspection will be turned off by default with the next major release of Kotlin (1.7). You might want to consider turning it on again if you think your codebase might benefit from having it. ","permalink":"https://arkadiuszchmura.com/posts/beware-of-the-order-of-operands-in-some-kotlin-collection-operations/","summary":"The order of operands can drastically affect the performance of your code.","title":"Beware of the order of operands in some Kotlin Collection operations"}]